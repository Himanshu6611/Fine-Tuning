# Fine-Tuning
This project demonstrates Supervised Fine-Tuning (SFT) of a GPT-2 model using a custom academic dataset (shoolini.txt). The model is adapted to better understand university, technical, and educational content. Training is performed with HuggingFace Transformers and PyTorch, and evaluated through inference testing on trained checkpoints.
